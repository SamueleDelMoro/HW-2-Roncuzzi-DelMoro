{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b189f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all packages\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import os, sys\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cccd032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "198a4dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio: \u001b[1mBeatles_LetItBe.wav\u001b[0m\n",
      "List of predicted chords: 180 elements.\n",
      "\n",
      "['D#m', 'D#m', 'B', 'D#m', 'E', 'A#m', 'D#m', 'D#m', 'D', 'Bm', 'B', 'Bm', 'D', 'Bm', 'F#m', 'C#', 'F#', 'F#', 'Bm', 'B', 'D#m', 'B', 'A#m', 'D#m', 'D#m', 'D', 'Bm', 'F#', 'B', 'D', 'D', 'F#m', 'F#', 'E', 'E', 'E', 'C#m', 'D', 'E', 'B', 'F#m', 'F#m', 'D', 'F#m', 'C#m', 'C#m', 'E', 'C#m', 'D', 'F#', 'D#m', 'C#', 'D#m', 'B', 'B', 'B', 'D#m', 'D#m', 'D#m', 'D', 'D', 'B', 'F#', 'Bm', 'D', 'F#', 'F#', 'F#', 'F#', 'B', 'D#m', 'D#m', 'D#m', 'D#m', 'B', 'D#m', 'D', 'Bm', 'Bm', 'Bm', 'D', 'Bm', 'F#', 'C#', 'E', 'E', 'Em', 'E', 'Bm', 'C#', 'F#m', 'D', 'F#m', 'D', 'F#m', 'C#m', 'C#', 'F#m', 'C#', 'D', 'C#', 'D#m', 'A#m', 'F#m', 'D#m', 'B', 'B', 'D#m', 'B', 'D#m', 'Bm', 'B', 'Bm', 'C#', 'Bm', 'F#', 'F#', 'F#', 'F#', 'F#', 'D#m', 'B', 'B', 'F#', 'B', 'B', 'B', 'Bm', 'F#', 'Bm', 'Bm', 'Bm', 'F#', 'C#', 'F#', 'E', 'E', 'Em', 'A', 'C#m', 'C#m', 'D', 'F#m', 'D', 'Bm', 'F#m', 'C#m', 'F#m', 'E', 'E', 'Bm', 'Dm', 'A#m', 'A#m', 'F#', 'B', 'F#', 'D#m', 'B', 'E', 'E', 'G#m', 'B', 'B', 'D#m', 'D#m', 'D#m', 'G#m', 'B', 'G#m', 'F', 'B', 'B', 'B', 'B', 'G#m', 'G#m', 'Bm', 'Bm', 'G']\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "'''Implement the template based chord recognition algorithm. Define a function that takes as input the\n",
    "path to a wav file and returns the estimated chords sequence labels.\n",
    "The output must be a list\n",
    "\n",
    "λ_pred = [λ_pred0, λpred_1, ..., λpred_N−1] (1)\n",
    "\n",
    "where each element λpred_n is the predicted chord label for the time frame n. \n",
    "The length of the list depends on the feature rate, i.e., both on the window length and hop size \n",
    "used for the chromagram computation and on the downsampling factor, if feature downsampling is \n",
    "applied.\n",
    "\n",
    "The chord templates to be considered are the major triads and the minor triads, leading to a total of 24 templates.\n",
    "Once the function is defined in the notebook, test the function on the wav file Beatles LetItBe.wav,\n",
    "available in /data/wav/ folder, and print or plot the output.\n",
    "\n",
    "Explain in the report the idea behind the template-based chord recognition algorithm and detail each\n",
    "step implemented in the code, including pre processing and post processing phases.\n",
    "'''\n",
    "template_cmaj = np.array([[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]]).T\n",
    "template_cmin = np.array([[1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]]).T\n",
    "\n",
    "\"\"\"\" Function use to generate the template matrix \"\"\"\n",
    "def generate_template_matrix(templates):\n",
    "    \n",
    "    template_matrix = np.zeros((12, 12 * templates.shape[1]))\n",
    "\n",
    "    for shift in range(12):\n",
    "        #np.roll: roll array elements along a given axis.\n",
    "        template_matrix[:, shift::12] = np.roll(templates, shift, axis=0)\n",
    "\n",
    "    return template_matrix\n",
    "\n",
    "templates = generate_template_matrix(np.concatenate((template_cmaj, template_cmin), axis=1))\n",
    "\n",
    "\"\"\"\" Labels for draw the chroma matrix \"\"\"\n",
    "\n",
    "chroma_label = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "chord_label_maj = chroma_label\n",
    "chord_label_min = [s + 'm' for s in chroma_label]\n",
    "chord_labels = chord_label_maj + chord_label_min\n",
    "\n",
    "\n",
    "\"\"\"Normalizes the columns of a feature sequence\"\"\"\n",
    "def normalize_feature_sequence(X, norm='2', threshold=0.0001, v=None):\n",
    "    \n",
    "    K, N = X.shape\n",
    "    X_norm = np.zeros((K, N))\n",
    "\n",
    "    if norm == '1':\n",
    "        if v is None:\n",
    "            v = np.ones(K, dtype=np.float64) / K\n",
    "        for n in range(N):\n",
    "            s = np.sum(np.abs(X[:, n]))\n",
    "            if s > threshold:\n",
    "                X_norm[:, n] = X[:, n] / s\n",
    "            else:\n",
    "                X_norm[:, n] = v\n",
    "\n",
    "    if norm == '2':\n",
    "        if v is None:\n",
    "            v = np.ones(K, dtype=np.float64) / np.sqrt(K)\n",
    "        for n in range(N):\n",
    "            s = np.sqrt(np.sum(X[:, n] ** 2))\n",
    "            if s > threshold:\n",
    "                X_norm[:, n] = X[:, n] / s\n",
    "            else:\n",
    "                X_norm[:, n] = v\n",
    "                \n",
    "    if norm == 'max':\n",
    "        if v is None:\n",
    "            v = np.ones(K)\n",
    "        for n in range(N):\n",
    "            s = np.max(np.abs(X[:, n]))\n",
    "            if s > threshold:\n",
    "                X_norm[:, n] = X[:, n] / s\n",
    "            else:\n",
    "                X_norm[:, n] = v\n",
    "\n",
    "    return X_norm\n",
    "\n",
    "#from scipy import signal\n",
    "\n",
    "def smooth_downsample_feature_sequence(X, Fs, filt_len=41, down_sampling=10, w_type='boxcar'):\n",
    "   \n",
    "    filt_kernel = np.expand_dims(signal.get_window(w_type, filt_len), axis=0)\n",
    "    X_smooth = signal.convolve(X, filt_kernel, mode='same') / filt_len\n",
    "    X_smooth = X_smooth[:, ::down_sampling]\n",
    "    Fs_feature = Fs / down_sampling\n",
    "    return X_smooth, Fs_feature\n",
    "\n",
    "def analysis_template_match(chromagram, templates, smoothing_window_length=None, smoothing_down_sampling=None,\n",
    "                            Fs=22050,\n",
    "                            norm_chromagram='2', norm_output='2'):\n",
    "    \n",
    "    chroma_normalized = normalize_feature_sequence(chromagram, norm=norm_chromagram)\n",
    "    \n",
    "    if smoothing_window_length and smoothing_down_sampling:\n",
    "        chroma_normalized, Fs_feat = smooth_downsample_feature_sequence(chroma_normalized, \n",
    "                                                                        down_sampling=smoothing_down_sampling,\n",
    "                                                                        filt_len=smoothing_window_length,\n",
    "                                                                        Fs=Fs)\n",
    "        \n",
    "    templates_normalized = normalize_feature_sequence(templates, norm=norm_chromagram)\n",
    "    \n",
    "    chord_similarity = np.matmul(templates_normalized.T, chroma_normalized)\n",
    "    \n",
    "    if norm_output:\n",
    "         chord_similarity = normalize_feature_sequence(chord_similarity, norm=norm_output)\n",
    "    \n",
    "    chord_max = (chord_similarity == chord_similarity.max(axis=0)).astype(int)\n",
    "\n",
    "    return chord_similarity, chord_max\n",
    "\n",
    "''''def chordList(templates, template_sequence):\n",
    "    input_list = [] \n",
    "\n",
    "    for col in range(chords_max.shape[1]-1): \n",
    "        if 1 in chords_max[:,col]: \n",
    "            index = np.where(chords_max[:,col] == 1)[0][0] \n",
    "            input_list.append(chords[index])\n",
    "    return input_list'''\n",
    "\n",
    "def chordList(templates, template_sequence):\n",
    "    template_sequence[template_sequence != 0] = 1 #highlights the notes well in the output matrix\n",
    "    chords = [] #initialize the chord list\n",
    "    \n",
    "    #analyses each sample of the audio matrix and the reference matrix by comparing them\n",
    "    #when the samples match assign the chord name to the chords array\n",
    "    for i in range(template_sequence.shape[1]):\n",
    "        for j in range(templates.shape[1]):\n",
    "            if(np.array_equal(template_sequence[:,i], templates[:,j])): \n",
    "                #majorChords\n",
    "                if(j==0):\n",
    "                    chords.append(\"C\")\n",
    "                if(j==1):\n",
    "                    chords.append(\"C#\")\n",
    "                if(j==2):\n",
    "                    chords.append(\"D\")\n",
    "                if(j==3):\n",
    "                    chords.append(\"D#\")\n",
    "                if(j==4):\n",
    "                    chords.append(\"E\")\n",
    "                if(j==5):\n",
    "                    chords.append(\"F\")\n",
    "                if(j==6):\n",
    "                    chords.append(\"F#\")\n",
    "                if(j==7):\n",
    "                    chords.append(\"G\")\n",
    "                if(j==8):\n",
    "                    chords.append(\"G#\")\n",
    "                if(j==9):\n",
    "                    chords.append(\"A\")\n",
    "                if(j==10):\n",
    "                    chords.append(\"A#\")   \n",
    "                if(j==11):\n",
    "                    chords.append(\"B\")\n",
    "                    \n",
    "                #minorChords\n",
    "                if(j==12):\n",
    "                    chords.append(\"Cm\")\n",
    "                if(j==13):\n",
    "                    chords.append(\"C#m\")\n",
    "                if(j==14):\n",
    "                    chords.append(\"Dm\")\n",
    "                if(j==15):\n",
    "                    chords.append(\"D#m\")\n",
    "                if(j==16):\n",
    "                    chords.append(\"Em\")\n",
    "                if(j==17):\n",
    "                    chords.append(\"Fm\")\n",
    "                if(j==18):\n",
    "                    chords.append(\"F#m\")\n",
    "                if(j==19):\n",
    "                    chords.append(\"Gm\")\n",
    "                if(j==20):\n",
    "                    chords.append(\"G#m\")\n",
    "                if(j==21):\n",
    "                    chords.append(\"Am\")\n",
    "                if(j==22):\n",
    "                    chords.append(\"A#m\")   \n",
    "                if(j==23):\n",
    "                    chords.append(\"Bm\")\n",
    "    return chords\n",
    "\n",
    "\n",
    "\n",
    "def template_based_chord_recognigtion(audioPath, L=None, D=None, norm = '2', N = 22050, H = 22050):\n",
    "    #Read audio\n",
    "    #x, Fs = librosa.load(audioPath, sr=Fs)\n",
    "    # load wav file\n",
    "    #fn_wav = os.path.join('data', 'audio', 'Beatles_LetItBe.wav')\n",
    "    #Parameters\n",
    "    Fs = 22050 \n",
    "    \n",
    "    if(N != Fs):\n",
    "        N = N\n",
    "    elif(N == Fs):\n",
    "        N = Fs\n",
    "        \n",
    "    if(H != N):\n",
    "        H = H\n",
    "    elif(H == N):\n",
    "        H = N\n",
    "\n",
    "    x, Fs = librosa.load(audioPath, sr=Fs)\n",
    "    notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B', 'Cm', 'C#m', 'Dm', 'D#m', 'Em', 'Fm', 'F#m', 'Gm', 'G#m', 'Am', 'A#m', 'Bm'];\n",
    "\n",
    "\n",
    "    X = librosa.stft(x, n_fft=N, hop_length=H, pad_mode='constant', center=True)\n",
    "\n",
    "    X = np.abs(X) ** 2\n",
    "        # a possible additional step is to use logarithmic compression \n",
    "    gamma = 0.1\n",
    "    X = np.log(1 + gamma * np.abs(X) ** 2)\n",
    "\n",
    "    C = librosa.feature.chroma_stft(S=X, sr=Fs, tuning=0, hop_length=H, n_fft=N, norm=None)\n",
    "\n",
    "\n",
    "    chords_sim, chords_max = analysis_template_match(C, templates, \n",
    "                                                         smoothing_window_length=None,\n",
    "                                                         smoothing_down_sampling=None,\n",
    "                                                         norm_chromagram='2', \n",
    "                                                         norm_output='max')\n",
    "\n",
    "    # Compute normalized binary templates of analysis\n",
    "    templates_normalized = normalize_feature_sequence(templates, norm='2')\n",
    "\n",
    "    # by multipling the most probable chords by the templates (normalized), you obtain the sequence of chords chroma\n",
    "    # by chroma\n",
    "\n",
    "    template_sequence = np.matmul(templates_normalized, chords_max)\n",
    "    chords = chordList(templates, template_sequence)\n",
    "    \n",
    "    return chords, template_sequence, templates, Fs, N, H\n",
    "    \n",
    "\n",
    "audioWav = os.path.join('data','wav', 'Beatles_PennyLane.wav')\n",
    "chordsList, template_sequence, templates, Fs, N, H = template_based_chord_recognigtion(audioWav)\n",
    "print('Audio: ' '\\033[1m' + 'Beatles_LetItBe.wav' + '\\033[0m')\n",
    "print('List of predicted chords: ' + str(len(chordsList))+ ' elements.\\n')\n",
    "print(chordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d2d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66ed5112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: \u001b[1mBeatles_LetItBe.csv\u001b[0m\n",
      "List of chords of the CSV file: 184 elements.\n",
      "\n",
      "['B', 'B', 'B', 'B', 'C#', 'F#', 'B', 'B', 'Bm', 'Bm', 'G#', 'G#', 'G', 'G', 'G', 'F#', 'F#', 'F#', 'F#', 'B', 'B', 'C#', 'F#', 'B', 'B', 'Bm', 'Bm', 'G#', 'G#', 'G', 'G', 'G', 'F#', 'F#', 'E', 'E', 'A', 'A', 'A', 'A', 'D', 'D', 'D', 'D', 'A', 'A', 'A', 'A', 'D', 'D', 'F#', 'F#', 'F#', 'B', 'B', 'C#', 'F#', 'B', 'B', 'Bm', 'Bm', 'G#', 'G#', 'G', 'G', 'F#', 'F#', 'F#', 'F#', 'F#', 'B', 'B', 'C#', 'F#', 'B', 'B', 'Bm', 'Bm', 'G#', 'G#', 'G', 'G', 'F#', 'F#', 'E', 'E', 'A', 'A', 'A', 'A', 'A', 'D', 'D', 'D', 'D', 'A', 'A', 'A', 'A', 'D', 'D', 'F#', 'F#', 'B', 'B', 'E', 'C#', 'F#', 'B', 'B', 'Bm', 'Bm', 'G#', 'G#', 'G', 'G', 'F#', 'F#', 'F#', 'F#', 'B', 'B', 'E', 'F#', 'B', 'B', 'B', 'Bm', 'Bm', 'G#', 'G#', 'G', 'G', 'F#', 'F#', 'E', 'E', 'A', 'A', 'A', 'A', 'D', 'D', 'D', 'D', 'D', 'A', 'A', 'A', 'A', 'D', 'D', 'F#', 'F#', 'B', 'B', 'B', 'B', 'E', 'E', 'E', 'E', 'B', 'B', 'B', 'B', 'B', 'E', 'E', 'E', 'E', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "'''\n",
    "Write a function to load and preprocess a reference annotation (or ground truth) file, saved in CSV\n",
    "format. The function should take as input the path to a CSV file and produce as output a list of ground\n",
    "truth chord labels, after suitable pre processing. The output must be a list\n",
    "\n",
    "λgt = [λgt0, λgt1, ..., λgtN−1] (2)\n",
    "\n",
    "where each element λgtn is the ground truth chord label for the time window n. \n",
    "The length of the list must be adapted to match the the feature rate.\n",
    "\n",
    "The reference annotations stored in the CSV file are given in the form of labelled segments, each\n",
    "specified as a triplet (start, end, λ) where start and end are expressed in seconds. To load the CSV file\n",
    "check the csv library (distributed with Python) or Pandas library (needs to be installed).\n",
    "\n",
    "In the preprocessing step you should\n",
    "• convert the segment-based annotation into a frame-based label sequence adapted to the feature rate\n",
    "used for the chroma sequence;\n",
    "• convert the labels used in the annotation file to match the chord labels used for the chord recognition\n",
    "algorithm in terms of enharmonic equivalence (i.e., Db = C# );\n",
    "\n",
    "• reduce the chord label set used in the annotation to match the chord labels set used for the chord\n",
    "recognition algorithm (i.e., DMaj6 → D); for this step you can choose any reduction strategy.\n",
    "\n",
    "Once the function is defined in the notebook, test the function on the CSV file Beatles LetItBe.csv,\n",
    "available in /data/csv/ folder, and print or plot the output.\n",
    "Explain in the report each step of the preprocessing phase, focusing in particular on the reduction\n",
    "strategy of the chord label set.\n",
    "'''\n",
    "\n",
    "#Read the CSV file from a path and return the list of chords of the csv adapted to length of the same list of the audio.\n",
    "def chordsCsv(path):\n",
    "    with open(path) as csv_file:\n",
    "        \n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        chords = [] #chords of csv\n",
    "        i = 0;\n",
    "        note = ['C','D','E','F','G','A','B']\n",
    "        \n",
    "        delta_csv = [] #time interval of each chords in seconds of the csv\n",
    "        for row in csv_reader:\n",
    "            \n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                delta_csv.append(row[1]) #extract the time interval of the chord\n",
    "                if \"min\" in row[2].split(':'):\n",
    "                    temp = row[2].split(':')[0]+'m' #change min in m\n",
    "                else:\n",
    "                    temp = row[2].split(':')[0] #extract the chord\n",
    "                chords.append(temp.split('/')[0]) #do the proper cut and add to the list\n",
    "\n",
    "        for e in chords:\n",
    "            if 'b' in e:\n",
    "                chords[i]=note[note.index(chords[i][0])-1]+'#' #change 'b' into '#'\n",
    "            i += 1   \n",
    "        \n",
    "       #For each time interval extract the number of repetitions of each chord in csv list.\n",
    "        delta_wav =  H / Fs #time interval of each frame of the audio    \n",
    "        chordsCSV_adapted = [] #list of the chords of csv adapted to the length of the list of the chords of the audio       \n",
    "        nRep = [] #number of repetitions of each chord of the csv\n",
    "        frame = 0 #counter of the frames\n",
    "        \n",
    "        for i in range(len(delta_csv)):\n",
    "            nRep_float = (float(delta_csv[i]) / delta_wav) - frame #extract number of repetitions in a frame of the audio\n",
    "            nRep.append(int(math.ceil(nRep_float))) #always round for excess\n",
    "            frame = (frame + nRep[i]) #increment the frame\n",
    "            \n",
    "        for i in range(len(chords)):\n",
    "            for j in range(nRep[i]):    \n",
    "                chordsCSV_adapted.append(chords[i]) #insert in the list the chord for its number of repetitions\n",
    "        \n",
    "        #Adapt the length of two lists by removing the last element from the longest one        \n",
    "        if (len(chordsCSV_adapted) != len(chords_WAV)): \n",
    "            diff = np.abs(len(chordsCSV_adapted) - len(chords_WAV))\n",
    "            for i in range(diff):\n",
    "                if(len(chordsCSV_adapted) > len(chords_WAV)):\n",
    "                    chordsCSV_adapted.pop() \n",
    "                elif (len(chords_WAV) > len(chordsCSV_adapted)):\n",
    "                    chords_WAV.pop()\n",
    "            \n",
    "    return chordsCSV_adapted\n",
    "\n",
    "audioCSV = os.path.join('data','csv', 'Beatles_PennyLane.csv') \n",
    "chords_CSV = chordsCsv(audioCSV);\n",
    "print('CSV: ' '\\033[1m' + 'Beatles_LetItBe.csv' + '\\033[0m')\n",
    "print('List of chords of the CSV file: ' + str(len(chords_CSV))+ ' elements.\\n')\n",
    "print(chords_CSV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b296f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d3a4931",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j2/ymhsh50s557dtkx3v23wqjq00000gn/T/ipykernel_6103/2839693064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0maudioWav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Beatles_PennyLane.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0maudioCSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Beatles_PennyLane.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mSongSuccess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mefficentAlg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioWav\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maudioCSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSongSuccess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j2/ymhsh50s557dtkx3v23wqjq00000gn/T/ipykernel_6103/2839693064.py\u001b[0m in \u001b[0;36mefficentAlg\u001b[0;34m(audioWav, audioCSV)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueChords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#print (chord,trueChords[chord])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueChords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mrecognizedChords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mnum_of_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m#print(chord,trueChords[chord]);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "'''\n",
    "Propose a metric for evaluating the template based chord recognition algorithm. \n",
    "A metric\n",
    "\n",
    "m = f(λ_pred,λ_gt) (3)\n",
    "\n",
    "is a scalar number that expresses how good is the algorithm in performing the task of chord recognition.\n",
    "The proposed metric should have higher values when the chord recognition algorithm is able to predict\n",
    "correctly the ground truth chords most of the times, lower values if the chord recognition algorithm often\n",
    "fails at recognising the chords.\n",
    "\n",
    "Write a function that takes as input the list of predicted chord labels, the list of ground truth chord\n",
    "labels and computes the proposed metric value. The two input lists must have same length and the\n",
    "output must be a scalar value.\n",
    "\n",
    "Once the function is defined in the notebook, test the function on the two lists of predicted and ground\n",
    "truth chord labels computed in Question 1 and Question 2.\n",
    "\n",
    "In the report write a formal definition of the proposed metric and thoroughly explain the idea behind\n",
    "the proposal. Can you imagine a musically informed strategy that weights differently mismatch errors of\n",
    "the chord recognition algorithm?\n",
    "'''\n",
    "notes_maj = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];\n",
    "notes_min = ['Cm', 'C#m', 'Dm', 'D#m', 'Em', 'Fm', 'F#m', 'Gm', 'G#m', 'Am', 'A#m', 'Bm'];\n",
    "\n",
    "\n",
    "#recognizedChords=chordList(templates, template_sequence);\n",
    "#da ultimare\n",
    "def efficentAlg(audioWav,audioCSV):\n",
    "    trueChords=chordsCsv(audioCSV);\n",
    "    chordsList, template_sequence, templates, Fs, N, H = template_based_chord_recognigtion(audioWav)\n",
    "    recognizedChords=chordsList;\n",
    "    #recognizedChords=['F', 'A', 'A', 'D', 'A#', 'A#', 'F', 'A#', 'D#', 'A#', 'F', 'A#', 'A#', 'F', 'Gm', 'A#', 'F', 'A#', 'A#', 'F', 'Gm', 'A#', 'F', 'A#', 'A#', 'F', 'A#', 'D#', 'A#', 'F', 'A#', 'A#', 'F', 'Gm', 'A#', 'F', 'A#', 'A#', 'F', 'Gm', 'A#', 'F', 'A#', 'D#', 'A#', 'A#', 'A#', 'A#', 'D#', 'A#', 'F', 'A#', 'F', 'A#', 'D#', 'A#', 'F', 'A#', 'A#', 'F', 'Gm', 'A#', 'F', 'A#', 'A#', 'F', 'Gm', 'A#', 'F', 'A#', 'D#', 'A#', 'A#', 'A#', 'A#', 'D#', 'A#', 'F', 'A#', 'F', 'A#', 'D#', 'A#', 'F', 'A#', 'A#', 'F', 'Gm', 'A#', 'F', 'A#', 'A#', 'F', 'Gm', 'A#', 'F', 'Gm', 'F', 'F', 'F', 'F', 'A#']\n",
    "    numChords=len(trueChords);\n",
    "    num_of_error=0;\n",
    "    imp_errors=[];\n",
    "\n",
    "    for chord in range(len(trueChords)):\n",
    "        #print (chord,trueChords[chord])\n",
    "        if(trueChords[chord]!=recognizedChords[chord]):\n",
    "            num_of_error += 1;\n",
    "            #print(chord,trueChords[chord]);\n",
    "            if(trueChords[chord] in notes_maj) :\n",
    "                if(recognizedChords[chord] in notes_maj):\n",
    "                    imp_errors.append(abs(notes_maj.index(trueChords[chord])- notes_maj.index(recognizedChords[chord]))+1);\n",
    "                else:\n",
    "                    imp_errors.append(abs(notes_maj.index(trueChords[chord])- notes_min.index(recognizedChords[chord]))+1);\n",
    "            else:\n",
    "                if(recognizedChords[chord] in notes_min):\n",
    "                    imp_errors.append(abs(notes_min.index(trueChords[chord])- notes_min.index(recognizedChords[chord]))+1);\n",
    "                else:\n",
    "                    imp_errors.append(abs(notes_min.index(trueChords[chord])- notes_maj.index(recognizedChords[chord]))+1);\n",
    "                    \n",
    "            #print(chord,trueChords[chord],imp_errors.pop());\n",
    "                \n",
    "                    \n",
    "            #calcolare la quantita dell'errore\n",
    "\n",
    "    if (num_of_error!=0):\n",
    "        #print(num_of_error,len(trueChords));\n",
    "        perc_success1=math.trunc((100-((num_of_error/numChords)*100)));\n",
    "        imp_errors_med=sum(imp_errors)/len(imp_errors);\n",
    "        perc_success2=math.trunc((100-((imp_errors_med/12)*100)));\n",
    "        return(perc_success1,perc_success2);\n",
    "\n",
    "    else:\n",
    "        return(100,0);\n",
    "\n",
    "audioWav = os.path.join('data','wav', 'Beatles_PennyLane.wav')\n",
    "audioCSV = os.path.join('data','csv', 'Beatles_PennyLane.csv') \n",
    "SongSuccess=efficentAlg(audioWav,audioCSV);\n",
    "print(SongSuccess);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348d520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "313793b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 55)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j2/ymhsh50s557dtkx3v23wqjq00000gn/T/ipykernel_6103/700927971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0maudioWav2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Beatles_PennyLane.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0maudioCSV2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Beatles_PennyLane.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mSongSuccess2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mefficentAlg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioWav2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maudioCSV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSongSuccess2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j2/ymhsh50s557dtkx3v23wqjq00000gn/T/ipykernel_6103/1821513479.py\u001b[0m in \u001b[0;36mefficentAlg\u001b[0;34m(audioWav, audioCSV)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueChords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#print (chord,trueChords[chord])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueChords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mrecognizedChords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mnum_of_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m#print(chord,trueChords[chord]);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Compute the proposed metric for the remaining 3 songs:\n",
    "• audio Beatles HereComesTheSun.wav, CSV Beatles HereComesTheSun.csv\n",
    "• audio Beatles PennyLane.wav, CSV Beatles PennyLane.csv\n",
    "• audio Beatles ObLaDiObLaDa.wav, CSV Beatles ObLaDiObLaDa.csv\n",
    "all contained in folders /data/wav/ and /data/csv/. Print or plot the metric values.\n",
    "'''\n",
    "\n",
    "#Here comes the sun\n",
    "audioWav1 = os.path.join('data','wav', 'Beatles_HereComesTheSun.wav')\n",
    "audioCSV1 = os.path.join('data','csv', 'Beatles_HereComesTheSun.csv')\n",
    "SongSuccess1=efficentAlg(audioWav1,audioCSV1);\n",
    "print(SongSuccess1)\n",
    "\n",
    "#PennyLane\n",
    "audioWav2 = os.path.join('data','wav', 'Beatles_PennyLane.wav')\n",
    "audioCSV2 = os.path.join('data','csv', 'Beatles_PennyLane.csv')\n",
    "SongSuccess2=efficentAlg(audioWav2,audioCSV2);\n",
    "print(SongSuccess2)\n",
    "\n",
    "#ObLaDiObLaDa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ff221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "959c826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRIC - SMOOTH LENGTH CHANGE\n",
      "Smoothing window lengths: [0, 10, 20]\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j2/ymhsh50s557dtkx3v23wqjq00000gn/T/ipykernel_6103/12128206.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mchords_WAV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplate_based_chord_recognigtion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchordsFromCsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Beatles_LetItBe.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mmetric1Str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmetric1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metric' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Analyse how algorithm parameters affect the performance of the templated based chord recognition\n",
    "algorithm.\n",
    "Given one algorithm parameter (i.e., smoothing filter length L), choose a range of 3 possible values\n",
    "for it (i.e.,L = [0, 10, 20] ). \n",
    "For each value of the parameter, compute the predicted labels and the correspondent metric value for each song.\n",
    "This produces a list of 3 metric values for each song.\n",
    "\n",
    "Plot the results for all songs in a figure where the x-axis corresponds to the parameter values, the\n",
    "y-axis corresponds to metric values. An example of the plot is in Figure 1.\n",
    "\n",
    "Repeat this for at least 3 different algorithm parameters. \n",
    "Note that in every experiment you need to change only one parameter value at a time, while the others must be fixed.\n",
    "\n",
    "Show the 3 plots both in the Jupyter Notebook and in the report. \n",
    "What considerations can you do from the 3 plots that you have? \n",
    "Are some algorithm parameters affecting the results more than others?\n",
    "Comment the results in the report.\n",
    "'''\n",
    "\n",
    "#Import audios of songs\n",
    "audio1 = os.path.join('data','wav', 'Beatles_LetItBe.wav')\n",
    "audio2 = os.path.join('data','wav', 'Beatles_HereComesTheSun.wav')\n",
    "audio3 = os.path.join('data','wav', 'Beatles_PennyLane.wav')\n",
    "audio4 = os.path.join('data','wav', 'Beatles_ObLaDiObLaDa.wav')\n",
    "\n",
    "#MODIFY THE LENGTH OF THE SMOOTHING WINDOW\n",
    "\n",
    "L = [0, 10, 20] #values of different lengths\n",
    "D = 1 #downsampling initial value\n",
    "\n",
    "print('METRIC - SMOOTH LENGTH CHANGE'+'\\nSmoothing window lengths: ' + str(L) + '\\n')\n",
    "\n",
    "#LetItBe\n",
    "metric1 = []\n",
    "metric1Str = []\n",
    "for i in range(len(L)):\n",
    "    chords_WAV, wav, templates, Fs, N, H = template_based_chord_recognigtion(audio1, L[i], D)\n",
    "    csv = chordsFromCsv(os.path.join('data','csv', 'Beatles_LetItBe.csv'))\n",
    "    m = metric(wav, csv)\n",
    "    metric1Str.append(str(m) + '%')\n",
    "    metric1.append(m)\n",
    "print(audio1[9:(len(audio1)-4)] + ': ' + '\\033[1m' + str(m1Str) + '\\033[0m')\n",
    "\n",
    "#HereComesTheSun\n",
    "metric2 = []\n",
    "metric2Str = []\n",
    "for i in range(len(L)):\n",
    "    chords_WAV, wav, templates, Fs, N, H = template_based_chord_recognigtion(audio2, L[i], D)\n",
    "    csv = chordsFromCsv(os.path.join('data','csv', 'Beatles_HereComesTheSun.csv'))\n",
    "    m = metric(wav, csv)\n",
    "    metric2Str.append(str(m) + '%')\n",
    "    metric2.append(m)\n",
    "print(audio2[9:(len(audio2)-4)] + ': ' + '\\033[1m' + str(m2Str) + '\\033[0m')\n",
    "\n",
    "#PennyLane\n",
    "metric3 = []\n",
    "metric3Str = []\n",
    "for i in range(len(L)):\n",
    "    chords_WAV, wav, templates, Fs, N, H = template_based_chord_recognigtion(audio3, L[i], D)\n",
    "    csv = chordsFromCsv(os.path.join('data','csv', 'Beatles_PennyLane.csv'))\n",
    "    m = metric(wav, csv)\n",
    "    metric3Str.append(str(m) + '%')\n",
    "    metric3.append(m)\n",
    "print(audio3[9:(len(audio3)-4)] + ': ' + '\\033[1m' + str(m3Str) + '\\033[0m')\n",
    "\n",
    "#ObLaDiObLaDa\n",
    "metric4 = []\n",
    "metric4Str = []\n",
    "for i in range(len(L)):\n",
    "    chords_WAV, wav, templates, Fs, N, H = template_based_chord_recognigtion(audio4, L[i], D)\n",
    "    csv = chordsFromCsv(os.path.join('data','csv', 'Beatles_ObLaDiObLaDa.csv'))\n",
    "    m = metric(wav, csv)\n",
    "    metric4Str.append(str(m) + '%')\n",
    "    metric4.append(m)\n",
    "print(audio4[9:(len(audio4)-4)] + ': ' + '\\033[1m' + str(m4Str) + '\\033[0m')\n",
    "\n",
    "#Plot \n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(L, metric1, marker='o', label = 'Let It Be')\n",
    "plt.plot(L, metric2, marker='o', label = 'Here Comes The Sun')\n",
    "plt.plot(L, metric3, marker='o', label = 'Penny Lane')\n",
    "plt.plot(L, metric4, marker='o', label = \"ObLaDiObLaDa\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.ylim([0,100])\n",
    "plt.xlabel('Smoothing Filter Length')\n",
    "plt.ylabel('Metric')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
